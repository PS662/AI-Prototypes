# Naive Neural Network

A simple multilayer perceptron (MLP) neural network implementation from scratch using NumPy.

## Overview

This prototype implements a basic feedforward neural network with:
- Configurable input, hidden, and output layers
- Backpropagation for training
- Sigmoid and tanh activation functions
- Momentum-based learning rate decay

## Usage

```bash
python nn_from_scratch.py
```

The demo trains on digit recognition using a 64-input, 100-hidden, 10-output architecture.
